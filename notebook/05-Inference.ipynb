{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e74af7b-c0e5-474e-bffe-fe0bccb5b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(os.path.abspath('/app/src/lib')) #import Dataloader\n",
    "sys.path.append(os.path.abspath('/app/src')) #for config\n",
    "\n",
    "from seed_everything import seed_everything\n",
    "import config\n",
    "config.HEADLESS_PLOT = False\n",
    "import utils\n",
    "\n",
    "seed_everything(config.SEED)\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "WINDOW_SIZE = 512          # Your TARGET_FLAG_LENGTH\n",
    "TARGET_SIZE = 512 # The FLAG_LENGTH the model uses\n",
    "STRIDE = 10                 # 1 = Check every single step (smoothest, but slowest)\n",
    "CONFIDENCE_THRESHOLD = 0.55 # Only classify if softmax prob > 70%\n",
    "BATCH_SIZE = config.BATCH_SIZE\n",
    "\n",
    "# Define your classes and their colors for the plot\n",
    "# Using the classes you mentioned earlier\n",
    "CLASS_CONFIG = {\n",
    "    0: {'name': 'Bearish Normal',  'color': 'red'},\n",
    "    1: {'name': 'Bearish Pennant', 'color': 'darkred'},\n",
    "    2: {'name': 'Bearish Wedge',   'color': 'orangered'},\n",
    "    3: {'name': 'Bullish Normal',  'color': 'green'},\n",
    "    4: {'name': 'Bullish Pennant', 'color': 'lime'},\n",
    "    5: {'name': 'Bullish Wedge',   'color': 'forestgreen'}\n",
    "}\n",
    "\n",
    "def preprocess_window(price_array, TARGET_LENGTH):\n",
    "    # 1. Normalize\n",
    "    seq_numpy = price_array.astype(np.float32)\n",
    "    if seq_numpy.max() - seq_numpy.min() > 0:\n",
    "        norm_seq = (seq_numpy - seq_numpy.min()) / (seq_numpy.max() - seq_numpy.min())\n",
    "    else:\n",
    "        norm_seq = seq_numpy - seq_numpy # All zeros if flat\n",
    "\n",
    "    # 2. Convert to Tensor\n",
    "    seq = torch.from_numpy(norm_seq)\n",
    "    \n",
    "    # 3. Force 3D Shape for Interpolate: (Batch=1, Channel=1, Length=Current)\n",
    "    seq = seq.view(1, 1, -1)\n",
    "    \n",
    "    # 4. Interpolate (Resize)\n",
    "    # Output shape will stay (1, 1, target_length)\n",
    "    seq = F.interpolate(seq, size=TARGET_LENGTH, mode='linear', align_corners=False)\n",
    "    \n",
    "    # 5. Return directly\n",
    "    # We already have (1, 1, 512), which is exactly what the model wants.\n",
    "    return seq.float()\n",
    "\n",
    "def run_inference(model, csv_path, output_csv_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Reads CSV, runs sliding window inference, saves results to CSV.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {csv_path}...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Ensure timestamp is datetime\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    prices = df['close'].values\n",
    "    timestamps = df['timestamp'].values\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"Running Inference...\")\n",
    "    # Loop through data using sliding window\n",
    "    # range(start, end, stride)\n",
    "    for i in tqdm(range(0, len(prices) - WINDOW_SIZE, STRIDE)):\n",
    "        \n",
    "        # 1. Get Window\n",
    "        window_prices = prices[i : i + WINDOW_SIZE]\n",
    "        window_start_time = timestamps[i]\n",
    "        window_end_time = timestamps[i + WINDOW_SIZE - 1]\n",
    "        \n",
    "        # 2. Preprocess\n",
    "        input_tensor = preprocess_window(window_prices, TARGET_SIZE).to(device)\n",
    "        \n",
    "        # 3. Model Prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_tensor)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            # Get max probability and class index\n",
    "            max_prob, predicted_idx = torch.max(probs, dim=1)\n",
    "            max_prob = max_prob.item()\n",
    "            predicted_idx = predicted_idx.item()\n",
    "        \n",
    "        # 4. Threshold Logic\n",
    "        if max_prob >= CONFIDENCE_THRESHOLD:\n",
    "            final_class = predicted_idx\n",
    "            class_name = CLASS_CONFIG[predicted_idx]['name']\n",
    "        else:\n",
    "            final_class = -1 # Unclassified / Low Confidence\n",
    "            class_name = \"Unclassified\"\n",
    "            \n",
    "        # 5. Store Result\n",
    "        results.append({\n",
    "            \"window_start_idx\": i,\n",
    "            \"window_end_idx\": i + WINDOW_SIZE,\n",
    "            \"start_time\": window_start_time,\n",
    "            \"end_time\": window_end_time,\n",
    "            \"predicted_class\": final_class,\n",
    "            \"class_name\": class_name,\n",
    "            \"confidence\": max_prob\n",
    "        })\n",
    "\n",
    "    # Save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Inference complete. Results saved to {output_csv_path}\")\n",
    "    \n",
    "    return df, results_df\n",
    "\n",
    "def plot_density_inference(original_df, results_df):\n",
    "    \"\"\"\n",
    "    Generates a separate density plot for EACH class detected in the results.\n",
    "    Only overlays for that specific class are shown, making it easy to judge\n",
    "    confidence by the 'darkness' of the color.\n",
    "    \"\"\"\n",
    "    print(\"Generating Density Plots per Class...\")\n",
    "    \n",
    "    # Filter out unclassified results (-1)\n",
    "    classified_df = results_df[results_df['predicted_class'] != -1]\n",
    "    \n",
    "    # Get the list of unique classes that were actually predicted\n",
    "    unique_classes = sorted(classified_df['predicted_class'].unique())\n",
    "    \n",
    "    if len(unique_classes) == 0:\n",
    "        print(\"No classes were detected above the threshold. No plots generated.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Detected flags for {unique_classes.length} classes\")\n",
    "\n",
    "    # Transparency level for layers. Lower = needs more overlap to get dark.\n",
    "    LAYER_ALPHA = 0.1 \n",
    "\n",
    "    # Loop through each detected class and create a separate plot\n",
    "    for cls_idx in unique_classes:\n",
    "        cls_idx = int(cls_idx)\n",
    "        class_name = CLASS_CONFIG[cls_idx]['name']\n",
    "        class_color = CLASS_CONFIG[cls_idx]['color']\n",
    "        \n",
    "        print(f\"Generating plot for class [{cls_idx}]: {class_name}...\")\n",
    "        \n",
    "        plt.figure(figsize=(15, 8), dpi=100)\n",
    "        \n",
    "        # 1. Plot the Base Price (Black line for context)\n",
    "        plt.plot(original_df.index, original_df['close'], color='black', linewidth=0.8, label='Price', alpha=0.5)\n",
    "        \n",
    "        # 2. Filter results just for this current class\n",
    "        class_results = classified_df[classified_df['predicted_class'] == cls_idx]\n",
    "        \n",
    "        # 3. Add Density Layers\n",
    "        # We use the class_color, but since it's the only overlay, \n",
    "        # you only need to look at the color intensity (darkness).\n",
    "        for _, row in tqdm(class_results.iterrows(), total=len(class_results), desc=f\"Layers for {class_name}\", leave=False):\n",
    "            start_x = int(row['window_start_idx'])\n",
    "            end_x = int(row['window_end_idx'])\n",
    "            \n",
    "            # Draw semi-transparent rectangle\n",
    "            plt.axvspan(start_x, end_x, color=class_color, alpha=LAYER_ALPHA, ec=None)\n",
    "\n",
    "        # 4. Formatting\n",
    "        plt.title(f\"Inference Density: {class_name.upper()}\\n(Darker = Overlaping flag intervals)\")\n",
    "        plt.xlabel(\"Time Index\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        \n",
    "        # Custom legend for just Price + This Class\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='black', lw=1, label='Price'),\n",
    "            Line2D([0], [0], color=class_color, lw=4, label=class_name, alpha=0.8)\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements, loc='upper left')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        # 5. Save with a unique filename per class\n",
    "        #safe_name = class_name.replace(' ', '_').lower()\n",
    "        #filename = f\"density_plot_class_{cls_idx}_{safe_name}.png\"\n",
    "        #plt.savefig(filename)\n",
    "        #print(f\"Saved: {filename}\")\n",
    "        \n",
    "        # Close figure to free memory so next loop starts fresh\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f598f0-6974-49b0-80d8-507dcdf8e264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../inference/EURUSD_5min_002.csv...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../inference/EURUSD_5min_002.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m FlagClassifier(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(config\u001b[38;5;241m.\u001b[39mMODEL_LOAD_PATH, map_location\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mDEVICE))\n\u001b[0;32m---> 10\u001b[0m input_df, pred_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../inference/EURUSD_5min_002.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minference_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m plot_density_inference(input_df, pred_df)\n",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(model, csv_path, output_csv_path, device)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mReads CSV, runs sliding window inference, saves results to CSV.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Ensure timestamp is datetime\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../inference/EURUSD_5min_002.csv'"
     ]
    }
   ],
   "source": [
    "from lib.dataloader import FlagDataset\n",
    "from lib.baseline_model import BaselineClassifier\n",
    "from lib.model import FlagClassifier\n",
    "from lib.seed_everything import seed_everything\n",
    "\n",
    "seed_everything(config.SEED)\n",
    "\n",
    "model = FlagClassifier(num_classes=6)\n",
    "model.load_state_dict(torch.load(config.MODEL_LOAD_PATH, map_location=config.DEVICE))\n",
    "input_df, pred_df = run_inference(model, \"/app/inference/EURUSD_5min_002.csv\", \"inference_results.csv\")\n",
    "plot_density_inference(input_df, pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61528b08-f658-4b7e-ab44-9562bfe6e25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75dc01-c099-4faf-bd4d-b883e4c190ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
